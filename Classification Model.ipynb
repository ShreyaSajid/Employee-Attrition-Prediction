{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Acquire Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exploratory Data Analysis and Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the csv file\n",
    "df = pd.read_csv(\"C:/Users/Shreya Sajid/Documents/Git/Employee-Attrition-Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DATA WRANGLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Drop Unnecessary/Unimportant Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Employee Number, Employee count, Standard Hours and Over18 are not required for this analysis and modelling. By dropping these features, we can increase accuracy.\n",
    "\n",
    "##### Reason - Standard Hours is constant (80 hrs) for all employees and all employees are over 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"EmployeeNumber\", axis = 1, inplace = True)\n",
    "df.drop(\"EmployeeCount\", axis = 1, inplace = True)\n",
    "df.drop(\"StandardHours\", axis = 1, inplace = True)\n",
    "df.drop(\"Over18\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>...</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1102</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>2</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>279</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1373</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1392</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>4</td>\n",
       "      <td>Female</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>591</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>Male</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n",
       "0   41       Yes      Travel_Rarely       1102                   Sales   \n",
       "1   49        No  Travel_Frequently        279  Research & Development   \n",
       "2   37       Yes      Travel_Rarely       1373  Research & Development   \n",
       "3   33        No  Travel_Frequently       1392  Research & Development   \n",
       "4   27        No      Travel_Rarely        591  Research & Development   \n",
       "\n",
       "   DistanceFromHome  Education EducationField  EnvironmentSatisfaction  \\\n",
       "0                 1          2  Life Sciences                        2   \n",
       "1                 8          1  Life Sciences                        3   \n",
       "2                 2          2          Other                        4   \n",
       "3                 3          4  Life Sciences                        4   \n",
       "4                 2          1        Medical                        1   \n",
       "\n",
       "   Gender  ...  PerformanceRating  RelationshipSatisfaction  StockOptionLevel  \\\n",
       "0  Female  ...                  3                         1                 0   \n",
       "1    Male  ...                  4                         4                 1   \n",
       "2    Male  ...                  3                         2                 0   \n",
       "3  Female  ...                  3                         3                 0   \n",
       "4    Male  ...                  3                         4                 1   \n",
       "\n",
       "  TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n",
       "0                 8                      0               1               6   \n",
       "1                10                      3               3              10   \n",
       "2                 7                      3               3               0   \n",
       "3                 8                      3               3               8   \n",
       "4                 6                      3               3               2   \n",
       "\n",
       "   YearsInCurrentRole  YearsSinceLastPromotion YearsWithCurrManager  \n",
       "0                   4                        0                    5  \n",
       "1                   7                        1                    7  \n",
       "2                   0                        0                    0  \n",
       "3                   7                        3                    0  \n",
       "4                   2                        2                    2  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Encode Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List categorical variables\n",
    "cat_var = ['Attrition','BusinessTravel','Department','EducationField','Gender','JobRole','MaritalStatus','OverTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_var:\n",
    "    df[i]=le.fit_transform(df[i].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         int64\n",
       "Attrition                   int32\n",
       "BusinessTravel              int32\n",
       "DailyRate                   int64\n",
       "Department                  int32\n",
       "DistanceFromHome            int64\n",
       "Education                   int64\n",
       "EducationField              int32\n",
       "EnvironmentSatisfaction     int64\n",
       "Gender                      int32\n",
       "HourlyRate                  int64\n",
       "JobInvolvement              int64\n",
       "JobLevel                    int64\n",
       "JobRole                     int32\n",
       "JobSatisfaction             int64\n",
       "MaritalStatus               int32\n",
       "MonthlyIncome               int64\n",
       "MonthlyRate                 int64\n",
       "NumCompaniesWorked          int64\n",
       "OverTime                    int32\n",
       "PercentSalaryHike           int64\n",
       "PerformanceRating           int64\n",
       "RelationshipSatisfaction    int64\n",
       "StockOptionLevel            int64\n",
       "TotalWorkingYears           int64\n",
       "TrainingTimesLastYear       int64\n",
       "WorkLifeBalance             int64\n",
       "YearsAtCompany              int64\n",
       "YearsInCurrentRole          int64\n",
       "YearsSinceLastPromotion     int64\n",
       "YearsWithCurrManager        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =pd.get_dummies(df, columns=['BusinessTravel','Department','EducationField','JobRole','MaritalStatus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>...</th>\n",
       "      <th>JobRole_2</th>\n",
       "      <th>JobRole_3</th>\n",
       "      <th>JobRole_4</th>\n",
       "      <th>JobRole_5</th>\n",
       "      <th>JobRole_6</th>\n",
       "      <th>JobRole_7</th>\n",
       "      <th>JobRole_8</th>\n",
       "      <th>MaritalStatus_0</th>\n",
       "      <th>MaritalStatus_1</th>\n",
       "      <th>MaritalStatus_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1102</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1373</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1392</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>591</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Attrition  DailyRate  DistanceFromHome  Education  \\\n",
       "0   41          1       1102                 1          2   \n",
       "1   49          0        279                 8          1   \n",
       "2   37          1       1373                 2          2   \n",
       "3   33          0       1392                 3          4   \n",
       "4   27          0        591                 2          1   \n",
       "\n",
       "   EnvironmentSatisfaction  Gender  HourlyRate  JobInvolvement  JobLevel  ...  \\\n",
       "0                        2       0          94               3         2  ...   \n",
       "1                        3       1          61               2         2  ...   \n",
       "2                        4       1          92               2         1  ...   \n",
       "3                        4       0          56               3         1  ...   \n",
       "4                        1       1          40               3         1  ...   \n",
       "\n",
       "   JobRole_2  JobRole_3  JobRole_4  JobRole_5  JobRole_6  JobRole_7  \\\n",
       "0          0          0          0          0          0          1   \n",
       "1          0          0          0          0          1          0   \n",
       "2          1          0          0          0          0          0   \n",
       "3          0          0          0          0          1          0   \n",
       "4          1          0          0          0          0          0   \n",
       "\n",
       "   JobRole_8  MaritalStatus_0  MaritalStatus_1  MaritalStatus_2  \n",
       "0          0                0                0                1  \n",
       "1          0                0                1                0  \n",
       "2          0                0                0                1  \n",
       "3          0                0                1                0  \n",
       "4          0                0                1                0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Predictive Modelling using Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To split the dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df.Attrition\n",
    "df.drop(['Attrition'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(df, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_report(y_true,y_pred):\n",
    "    print(\"Accuracy = \",accuracy_score(y_true,y_pred))\n",
    "    print(\"Recall = \",recall_score(y_true,y_pred))\n",
    "    print(\"Precision = \",precision_score(y_true,y_pred))\n",
    "    print(\"F1 Score = \",f1_score(y_true,y_pred))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE - Over Sampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\shreya sajid\\appdata\\roaming\\python\\python37\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\shreya sajid\\appdata\\roaming\\python\\python37\\site-packages (from imblearn) (0.7.0)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in c:\\users\\shreya sajid\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.23.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\shreya sajid\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\shreya sajid\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\shreya sajid\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\shreya sajid\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->imbalanced-learn->imblearn) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "#Install SMOTE\n",
    "! pip install imblearn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "from imblearn import under_sampling\n",
    "from imblearn import over_sampling\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampler = SMOTE(random_state=0)\n",
    "smote_train, smote_target = oversampler.fit_sample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weights\n",
    "\n",
    "It is necessary to balance the class weights as we are dealing with an imbalanced data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_classes = list(Y_train.unique())\n",
    "unique_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight of a class = No. of samples/ (No. of Classes * No. of samples for a particular class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {}\n",
    "for classes in unique_classes:\n",
    "    out_dict[classes] = Y_train.shape[0]/((Y_train.loc[Y_train == classes].shape[0]) * len(unique_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 2.946107784431138, 0: 0.602203182374541}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from math import sqrt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score =  0.8302845528455285\n",
      "RMSE =  0.4119653470311205\n"
     ]
    }
   ],
   "source": [
    "#TRAIN SCORE\n",
    "Y_pred = logreg.predict(X_train)\n",
    "acc_log = accuracy_score(Y_train,Y_pred)\n",
    "print(\"Train Score = \",acc_log)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_train, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score =  0.8559670781893004\n",
      "RMSE =  0.3795166950355407\n"
     ]
    }
   ],
   "source": [
    "#TEST SCORE\n",
    "Y_pred = logreg.predict(X_test)\n",
    "acc_log_test = accuracy_score(Y_test,Y_pred)\n",
    "print(\"Test Score = \",acc_log_test)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 Using SMOTE - Over Sampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6707818930041153\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.69      0.78       416\n",
      "           1       0.23      0.54      0.32        70\n",
      "\n",
      "    accuracy                           0.67       486\n",
      "   macro avg       0.56      0.62      0.55       486\n",
      "weighted avg       0.80      0.67      0.72       486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(smote_train, smote_target)\n",
    "Y_pred = logreg.predict(X_test)\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(Y_test, Y_pred)))\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Class Weight - To tackle the imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "logreg = LogisticRegression(class_weight = 'balanced').fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60220318, 2.94610778])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight.compute_class_weight('balanced',np.unique(Y_train),Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual      0   1\n",
       "Predicted        \n",
       "0          78  18\n",
       "1          55   8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "pd.crosstab(pd.Series(Y_pred, name = 'Predicted'),\n",
    "           pd.Series(Y_test, name = 'Actual'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many samples are falsely classified as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL REPORT:\n",
      "Accuracy =  0.6049382716049383\n",
      "Recall =  0.6285714285714286\n",
      "Precision =  0.20952380952380953\n",
      "F1 Score =  0.3142857142857143\n"
     ]
    }
   ],
   "source": [
    "#Generate the model report\n",
    "print(\"MODEL REPORT:\")\n",
    "model_report(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GridSearch to obtain an optimal set of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters : {'class_weight': {0: 0.23947368421052628, 1: 0.7605263157894737}}\n"
     ]
    }
   ],
   "source": [
    "weights = np.linspace(0.05, 0.95, 20)\n",
    "gsc = GridSearchCV(\n",
    "    estimator=LogisticRegression(),\n",
    "    param_grid={\n",
    "        'class_weight': [{0: x, 1: 1.0-x} for x in weights]\n",
    "    },\n",
    "    scoring='f1',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "grid_result = gsc.fit(X_train, Y_train)\n",
    "print(\"Best parameters : %s\" % grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(**grid_result.best_params_).fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>116</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual       0   1\n",
       "Predicted         \n",
       "0          116  23\n",
       "1           17   3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "pd.crosstab(pd.Series(Y_pred, name = 'Predicted'),\n",
    "           pd.Series(Y_test, name = 'Actual'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL REPORT:\n",
      "Accuracy =  0.8065843621399177\n",
      "Recall =  0.38571428571428573\n",
      "Precision =  0.34615384615384615\n",
      "F1 Score =  0.3648648648648648\n"
     ]
    }
   ],
   "source": [
    "#Generate the model report\n",
    "print(\"MODEL REPORT:\")\n",
    "model_report(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 K Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model\n",
    "knn = KNeighborsClassifier(n_neighbors = 3) \n",
    "knn.fit(X_train, Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score =  0.8709349593495935\n",
      "RMSE =  0.3592562325839407\n"
     ]
    }
   ],
   "source": [
    "Y_pred = knn.predict(X_train)  \n",
    "acc_knn = accuracy_score(Y_train,Y_pred)\n",
    "print(\"Train Score = \",acc_knn)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_train, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score =  0.8106995884773662\n",
      "RMSE =  0.4350866712766937\n"
     ]
    }
   ],
   "source": [
    "Y_pred = knn.predict(X_test)  \n",
    "acc_knn_test = accuracy_score(Y_test,Y_pred)\n",
    "print(\"Test Score = \",acc_knn_test)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Using SMOTE - Over Sampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6378600823045267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.76       416\n",
      "           1       0.18      0.41      0.25        70\n",
      "\n",
      "    accuracy                           0.64       486\n",
      "   macro avg       0.52      0.54      0.50       486\n",
      "weighted avg       0.77      0.64      0.69       486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn.fit(smote_train, smote_target)\n",
    "Y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(Y_test, Y_pred)))\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model\n",
    "gaussian = GaussianNB() \n",
    "gaussian.fit(X_train, Y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score =  0.8709349593495935\n",
      "RMSE =  0.5\n"
     ]
    }
   ],
   "source": [
    "Y_pred = gaussian.predict(X_train)  \n",
    "acc_gaussian = accuracy_score(Y_train,Y_pred)\n",
    "print(\"Train Score = \",acc_knn)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_train, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score =  0.8106995884773662\n",
      "RMSE =  0.5211573066470477\n"
     ]
    }
   ],
   "source": [
    "Y_pred = gaussian.predict(X_test)  \n",
    "acc_gaussian_test = accuracy_score(Y_test,Y_pred)\n",
    "print(\"Test Score = \",acc_knn_test)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Using SMOTE - Over Sampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6584362139917695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.67      0.77       416\n",
      "           1       0.23      0.57      0.33        70\n",
      "\n",
      "    accuracy                           0.66       486\n",
      "   macro avg       0.57      0.62      0.55       486\n",
      "weighted avg       0.81      0.66      0.71       486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaussian.fit(smote_train, smote_target)\n",
    "Y_pred = gaussian.predict(X_test)\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(Y_test, Y_pred)))\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model\n",
    "svc = SVC()\n",
    "svc.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score =  0.8302845528455285\n",
      "RMSE =  0.4119653470311205\n"
     ]
    }
   ],
   "source": [
    "Y_pred = svc.predict(X_train)\n",
    "\n",
    "acc_svc = accuracy_score(Y_train,Y_pred)\n",
    "print(\"Train Score = \",acc_svc)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_train, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score =  0.8559670781893004\n",
      "RMSE =  0.3795166950355407\n"
     ]
    }
   ],
   "source": [
    "Y_pred = svc.predict(X_test)\n",
    "acc_svc_test = accuracy_score(Y_test,Y_pred)\n",
    "print(\"Test Score = \",acc_svc_test)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Using SMOTE - Over Sampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.5349794238683128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.52      0.66       416\n",
      "           1       0.18      0.61      0.28        70\n",
      "\n",
      "    accuracy                           0.53       486\n",
      "   macro avg       0.53      0.57      0.47       486\n",
      "weighted avg       0.79      0.53      0.60       486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc.fit(smote_train, smote_target)\n",
    "Y_pred = svc.predict(X_test)\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(Y_test, Y_pred)))\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Class weight - To tackle the imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "svc = SVC(class_weight = 'balanced').fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60220318, 2.94610778])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight.compute_class_weight('balanced',np.unique(Y_train),Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual      0   1\n",
       "Predicted        \n",
       "0          54  14\n",
       "1          79  12"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "pd.crosstab(pd.Series(Y_pred, name = 'Predicted'),\n",
    "           pd.Series(Y_test, name = 'Actual'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL REPORT:\n",
      "Accuracy =  0.5\n",
      "Recall =  0.6857142857142857\n",
      "Precision =  0.17843866171003717\n",
      "F1 Score =  0.2831858407079646\n"
     ]
    }
   ],
   "source": [
    "#Generate the model report\n",
    "print(\"MODEL REPORT:\")\n",
    "model_report(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GridSearch to obtain an optimal set of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters : {'class_weight': {0: 0.19210526315789472, 1: 0.8078947368421052}}\n"
     ]
    }
   ],
   "source": [
    "weights = np.linspace(0.05, 0.95, 20)\n",
    "gsc = GridSearchCV(\n",
    "    estimator=SVC(),\n",
    "    param_grid={\n",
    "        'class_weight': [{0: x, 1: 1.0-x} for x in weights]\n",
    "    },\n",
    "    scoring='f1',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "grid_result = gsc.fit(X_train, Y_train)\n",
    "print(\"Best parameters : %s\" % grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(**grid_result.best_params_).fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual      0   1\n",
       "Predicted        \n",
       "0          64  16\n",
       "1          69  10"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "pd.crosstab(pd.Series(Y_pred, name = 'Predicted'),\n",
    "           pd.Series(Y_test, name = 'Actual'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL REPORT:\n",
      "Accuracy =  0.551440329218107\n",
      "Recall =  0.5857142857142857\n",
      "Precision =  0.1782608695652174\n",
      "F1 Score =  0.2733333333333333\n"
     ]
    }
   ],
   "source": [
    "#Generate the model report\n",
    "print(\"MODEL REPORT:\")\n",
    "model_report(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model\n",
    "decision_tree = DecisionTreeClassifier() \n",
    "decision_tree.fit(X_train, Y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score =  1.0\n",
      "RMSE =  0.0\n"
     ]
    }
   ],
   "source": [
    "Y_pred = decision_tree.predict(X_train)  \n",
    "acc_decision_tree = accuracy_score(Y_train,Y_pred)\n",
    "print(\"Train Score = \",acc_decision_tree)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_train, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score =  0.8127572016460906\n",
      "RMSE =  0.4327156090943675\n"
     ]
    }
   ],
   "source": [
    "Y_pred = decision_tree.predict(X_test)  \n",
    "acc_decision_tree_test = accuracy_score(Y_test,Y_pred)\n",
    "print(\"Test Score = \",acc_decision_tree_test)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2 Using SMOTE - Over Sampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7592592592592593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.83      0.86       416\n",
      "           1       0.25      0.33      0.28        70\n",
      "\n",
      "    accuracy                           0.76       486\n",
      "   macro avg       0.56      0.58      0.57       486\n",
      "weighted avg       0.79      0.76      0.77       486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decision_tree.fit(smote_train, smote_target)\n",
    "Y_pred = decision_tree.predict(X_test)\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(Y_test, Y_pred)))\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3 Class Weight - To tackle the imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "decision_tree = DecisionTreeClassifier(class_weight = 'balanced').fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60220318, 2.94610778])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight.compute_class_weight('balanced',np.unique(Y_train),Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual       0   1\n",
       "Predicted         \n",
       "0          112  21\n",
       "1           21   5"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "pd.crosstab(pd.Series(Y_pred, name = 'Predicted'),\n",
    "           pd.Series(Y_test, name = 'Actual'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL REPORT:\n",
      "Accuracy =  0.8024691358024691\n",
      "Recall =  0.32857142857142857\n",
      "Precision =  0.3194444444444444\n",
      "F1 Score =  0.323943661971831\n"
     ]
    }
   ],
   "source": [
    "#Generate the model report\n",
    "print(\"MODEL REPORT:\")\n",
    "model_report(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GridSearch to obtain an optimal set of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters : {'class_weight': {0: 0.6657894736842105, 1: 0.3342105263157895}}\n"
     ]
    }
   ],
   "source": [
    "weights = np.linspace(0.05, 0.95, 20)\n",
    "gsc = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    param_grid={\n",
    "        'class_weight': [{0: x, 1: 1.0-x} for x in weights]\n",
    "    },\n",
    "    scoring='f1',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "grid_result = gsc.fit(X_train, Y_train)\n",
    "print(\"Best parameters : %s\" % grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(**grid_result.best_params_).fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = decision_tree.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual       0   1\n",
       "Predicted         \n",
       "0          115  23\n",
       "1           18   3"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "pd.crosstab(pd.Series(Y_pred, name = 'Predicted'),\n",
    "           pd.Series(Y_test, name = 'Actual'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL REPORT:\n",
      "Accuracy =  0.7757201646090535\n",
      "Recall =  0.34285714285714286\n",
      "Precision =  0.27586206896551724\n",
      "F1 Score =  0.3057324840764331\n"
     ]
    }
   ],
   "source": [
    "#Generate the model report\n",
    "print(\"MODEL REPORT:\")\n",
    "model_report(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.1 Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=7, max_features=1, min_samples_split=25)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model\n",
    "random_forest = RandomForestClassifier(n_estimators=100,min_samples_split=25,max_depth=7,max_features=1)\n",
    "random_forest.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score =  0.8302845528455285\n",
      "RMSE =  0.4119653470311205\n"
     ]
    }
   ],
   "source": [
    "Y_pred = random_forest.predict(X_train)\n",
    "\n",
    "acc_random_forest = accuracy_score(Y_train,Y_pred)\n",
    "print(\"Train Score = \",acc_random_forest)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_train, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score =  0.8559670781893004\n",
      "RMSE =  0.3795166950355407\n"
     ]
    }
   ],
   "source": [
    "Y_pred = random_forest.predict(X_test)\n",
    "acc_random_forest_test = accuracy_score(Y_test,Y_pred)\n",
    "print(\"Test Score = \",acc_random_forest_test)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.2 Using SMOTE - Over Sampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8415637860082305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91       416\n",
      "           1       0.43      0.31      0.36        70\n",
      "\n",
      "    accuracy                           0.84       486\n",
      "   macro avg       0.66      0.62      0.64       486\n",
      "weighted avg       0.82      0.84      0.83       486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest.fit(smote_train, smote_target)\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(Y_test, Y_pred)))\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### While using SMOTE to deal with the imbalanced data, we infer that Random Forest model is the best as per the classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will perform K-fold cross validation with 10 folds to output an array of 10 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Scores: [0.82828283 0.82828283 0.82828283 0.82828283 0.82653061 0.82653061\n",
      " 0.82653061 0.83673469 0.83673469 0.83673469]\n",
      "Mean: 0.830292723149866\n",
      "Standard Deviation: 0.004279206765968074\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(random_forest, X_train, Y_train, cv=10, scoring = \"accuracy\")\n",
    "print(\"Train Scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Scores: [0.85714286 0.85714286 0.85714286 0.85714286 0.85714286 0.85714286\n",
      " 0.85416667 0.85416667 0.85416667 0.85416667]\n",
      "Mean: 0.855952380952381\n",
      "Standard Deviation: 0.0014580296087995056\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(random_forest, X_test, Y_test, cv=10, scoring = \"accuracy\")\n",
    "print(\"Test Scores:\", scores)\n",
    "print(\"Mean:\", scores.mean())\n",
    "print(\"Standard Deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.3 Class Weight - To tackle the imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "random_forest = RandomForestClassifier(class_weight = 'balanced').fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60220318, 2.94610778])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight.compute_class_weight('balanced',np.unique(Y_train),Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual       0   1\n",
       "Predicted         \n",
       "0          130  25\n",
       "1            3   1"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "pd.crosstab(pd.Series(Y_pred, name = 'Predicted'),\n",
    "           pd.Series(Y_test, name = 'Actual'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL REPORT:\n",
      "Accuracy =  0.8641975308641975\n",
      "Recall =  0.1\n",
      "Precision =  0.7\n",
      "F1 Score =  0.175\n"
     ]
    }
   ],
   "source": [
    "#Generate the model report\n",
    "print(\"MODEL REPORT:\")\n",
    "model_report(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GridSearch to obtain an optimal set of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters : {'class_weight': {0: 0.9026315789473683, 1: 0.09736842105263166}}\n"
     ]
    }
   ],
   "source": [
    "weights = np.linspace(0.05, 0.95, 20)\n",
    "gsc = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid={\n",
    "        'class_weight': [{0: x, 1: 1.0-x} for x in weights]\n",
    "    },\n",
    "    scoring='f1',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "grid_result = gsc.fit(X_train, Y_train)\n",
    "print(\"Best parameters : %s\" % grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(**grid_result.best_params_).fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual       0   1\n",
       "Predicted         \n",
       "0          131  24\n",
       "1            2   2"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "pd.crosstab(pd.Series(Y_pred, name = 'Predicted'),\n",
    "           pd.Series(Y_test, name = 'Actual'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL REPORT:\n",
      "Accuracy =  0.8744855967078189\n",
      "Recall =  0.21428571428571427\n",
      "Precision =  0.7142857142857143\n",
      "F1 Score =  0.32967032967032966\n"
     ]
    }
   ],
   "source": [
    "#Generate the model report\n",
    "print(\"MODEL REPORT:\")\n",
    "model_report(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.1 Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(learning_rate=0.05, max_depth=5)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model\n",
    "xgb = XGBClassifier(learning_rate = 0.05, n_estimators=100, max_depth=5)\n",
    "xgb.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score =  0.967479674796748\n",
      "RMSE =  0.18033392693348646\n"
     ]
    }
   ],
   "source": [
    "Y_pred = xgb.predict(X_train)\n",
    "acc_xgb = accuracy_score(Y_train,Y_pred)\n",
    "print(\"Train Score = \",acc_xgb)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_train, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score =  0.8683127572016461\n",
      "RMSE =  0.36288736930121157\n"
     ]
    }
   ],
   "source": [
    "Y_pred = xgb.predict(X_test)\n",
    "acc_xgb = accuracy_score(Y_test,Y_pred)\n",
    "print(\"Test Score = \",acc_xgb)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.2 Using SMOTE - Over Sampling Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8518518518518519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92       416\n",
      "           1       0.47      0.23      0.31        70\n",
      "\n",
      "    accuracy                           0.85       486\n",
      "   macro avg       0.68      0.59      0.61       486\n",
      "weighted avg       0.82      0.85      0.83       486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(smote_train, smote_target)\n",
    "Y_pred = xgb.predict(X_test)\n",
    "print(\"Accuracy score: {}\".format(accuracy_score(Y_test, Y_pred)))\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7.3 Class Weight - To tackle the imbalance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "xgb = XGBClassifier(class_weight = 'balanced').fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60220318, 2.94610778])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight.compute_class_weight('balanced',np.unique(Y_train),Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual       0   1\n",
       "Predicted         \n",
       "0          127  23\n",
       "1            6   3"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "pd.crosstab(pd.Series(Y_pred, name = 'Predicted'),\n",
    "           pd.Series(Y_test, name = 'Actual'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL REPORT:\n",
      "Accuracy =  0.8765432098765432\n",
      "Recall =  0.24285714285714285\n",
      "Precision =  0.7083333333333334\n",
      "F1 Score =  0.36170212765957444\n"
     ]
    }
   ],
   "source": [
    "#Generate the model report\n",
    "print(\"MODEL REPORT:\")\n",
    "model_report(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create param grid object \n",
    "forest_params = dict(     \n",
    "    max_depth = [n for n in range(9, 14)],     \n",
    "    min_samples_split = [n for n in range(4, 11)], \n",
    "    min_samples_leaf = [n for n in range(2, 5)],     \n",
    "    n_estimators = [n for n in range(10, 60, 10)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate Random Forest model\n",
    "forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [9, 10, 11, 12, 13],\n",
       "                         'min_samples_leaf': [2, 3, 4],\n",
       "                         'min_samples_split': [4, 5, 6, 7, 8, 9, 10],\n",
       "                         'n_estimators': [10, 20, 30, 40, 50]})"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build and fit model \n",
    "forest_cv = GridSearchCV(estimator=forest, param_grid=forest_params, cv=5) \n",
    "forest_cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8607893918988916\n",
      "Optimal params: RandomForestClassifier(max_depth=13, min_samples_leaf=2, min_samples_split=7,\n",
      "                       n_estimators=20)\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(forest_cv.best_score_))\n",
    "print(\"Optimal params: {}\".format(forest_cv.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score =  0.9502032520325203\n",
      "RMSE =  0.2231518495721684\n"
     ]
    }
   ],
   "source": [
    "Y_pred = forest_cv.predict(X_train)\n",
    "acc_random_forest = accuracy_score(Y_train,Y_pred)\n",
    "print(\"Train Score = \",acc_random_forest)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_train, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score =  0.8662551440329218\n",
      "RMSE =  0.3657114381135463\n"
     ]
    }
   ],
   "source": [
    "Y_pred = forest_cv.predict(X_test)\n",
    "acc_random_forest_test = accuracy_score(Y_test,Y_pred)\n",
    "print(\"Test Score = \",acc_random_forest_test)\n",
    "\n",
    "#RMSE\n",
    "rmse = sqrt(mean_squared_error(Y_test, Y_pred))\n",
    "print(\"RMSE = \",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL REPORT:\n",
      "Accuracy =  0.8662551440329218\n",
      "Recall =  0.14285714285714285\n",
      "Precision =  0.6666666666666666\n",
      "F1 Score =  0.23529411764705882\n"
     ]
    }
   ],
   "source": [
    "#Generate the model report\n",
    "print(\"MODEL REPORT:\")\n",
    "model_report(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 Model Accuracy and Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.9.1 Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN SCORES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.950203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.870935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.868313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.830285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>0.830285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model     Score\n",
       "4            Decision Tree  1.000000\n",
       "5            Random Forest  0.950203\n",
       "1                      KNN  0.870935\n",
       "6                  XGBoost  0.868313\n",
       "0      Logistic Regression  0.830285\n",
       "3  Support Vector Machines  0.830285\n",
       "2              Naive Bayes  0.750000"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'KNN','Naive Bayes','Support Vector Machines','Decision Tree','Random Forest','XGBoost'],\n",
    "    'Score': [acc_log, acc_knn, acc_gaussian, acc_svc, acc_decision_tree, acc_random_forest,acc_xgb]})\n",
    "df_result = results.sort_values(by='Score', ascending=False)\n",
    "#Display\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST SCORES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.868313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.866255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.855967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>0.855967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.812757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.810700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.728395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model     Score\n",
       "6                  XGBoost  0.868313\n",
       "5            Random Forest  0.866255\n",
       "0      Logistic Regression  0.855967\n",
       "3  Support Vector Machines  0.855967\n",
       "4            Decision Tree  0.812757\n",
       "1                      KNN  0.810700\n",
       "2              Naive Bayes  0.728395"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'KNN','Naive Bayes','Support Vector Machines','Decision Tree','Random Forest','XGBoost'],\n",
    "    'Score': [acc_log_test, acc_knn_test, acc_gaussian_test, acc_svc_test, acc_decision_tree_test, acc_random_forest_test,acc_xgb]})\n",
    "df_result = results.sort_values(by='Score', ascending=False)\n",
    "#Display\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### INFERENCE:\n",
    "\n",
    "According to accuracy scores, XGBoost and RandomForest seem to be the best models. But for an imbalanced dataset, it is better to look at f1 scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now apply class weight to XGBoost model using SMOTE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "xgb = XGBClassifier(class_weight = 'balanced').fit(smote_train,smote_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight.compute_class_weight('balanced',np.unique(smote_target),smote_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual       0   1\n",
       "Predicted         \n",
       "0          120  24\n",
       "1           13   2"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "pd.crosstab(pd.Series(Y_pred, name = 'Predicted'),\n",
    "           pd.Series(Y_test, name = 'Actual'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL REPORT:\n",
      "Accuracy =  0.8724279835390947\n",
      "Recall =  0.38571428571428573\n",
      "Precision =  0.5869565217391305\n",
      "F1 Score =  0.46551724137931033\n"
     ]
    }
   ],
   "source": [
    "#Generate the model report\n",
    "print(\"MODEL REPORT:\")\n",
    "model_report(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using GridSearch to obtain an optimal set of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters : {'class_weight': {0: 0.05, 1: 0.95}}\n"
     ]
    }
   ],
   "source": [
    "weights = np.linspace(0.05, 0.95, 20)\n",
    "gsc = GridSearchCV(\n",
    "    estimator=XGBClassifier(),\n",
    "    param_grid={\n",
    "        'class_weight': [{0: x, 1: 1.0-x} for x in weights]\n",
    "    },\n",
    "    scoring='f1',\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "grid_result = gsc.fit(X_train, Y_train)\n",
    "print(\"Best parameters : %s\" % grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(**grid_result.best_params_).fit(smote_train,smote_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Actual</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Actual       0   1\n",
       "Predicted         \n",
       "0          128  26\n",
       "1            5   0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CONFUSION MATRIX\n",
    "pd.crosstab(pd.Series(Y_pred, name = 'Predicted'),\n",
    "           pd.Series(Y_test, name = 'Actual'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL REPORT:\n",
      "Accuracy =  0.8559670781893004\n",
      "Recall =  0.14285714285714285\n",
      "Precision =  0.5\n",
      "F1 Score =  0.22222222222222224\n"
     ]
    }
   ],
   "source": [
    "#Generate the model report\n",
    "print(\"MODEL REPORT:\")\n",
    "model_report(Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost:\n",
    "XGBoost seems to be the best model as it does not overfit and has handled the imbalanced data set well with the help of class_weight. When using SMOTE, the F1 score is 0.46. And after balancing the class weights, we obtained a precision of 0.7 and an accuracy of 0.87."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
